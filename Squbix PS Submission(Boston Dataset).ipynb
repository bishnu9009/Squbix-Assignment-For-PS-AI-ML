{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b505de-67fe-4af7-8a72-2af72f35701a",
   "metadata": {},
   "source": [
    "<center><h1>Housing Price Prediction(Boston Dataset)</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31893e13-0711-48f4-b242-b6df28de17d5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h4>\n",
    "    Prerequisite Installations\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c5eb4-86c7-4ca5-bebe-b532486e0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0ab6d-8594-46c0-a882-1e9ad0a9a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit pandas numpy joblib scikit-learn seaborn math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf24d98-cbc5-4698-a7f8-b054c3df5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6258fd6-24f4-4975-9c55-226799dcbf7b",
   "metadata": {},
   "source": [
    "- The following file contains machine learning model(s) which are created using Scikit learn library. These models can be used to predict prices of houses based upon certain criteria which are taken as their inputs and given out as their outputs.\n",
    "- The dataset used is based on the 'Boston Housing dataset' available on kaggle.\n",
    "- Boston : <href>https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset</href>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1bad8-a756-47b7-aeaf-dfbf65cbc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary python Libraries and Dependancies.\n",
    "import os\n",
    "import joblib\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e36cc-7de3-4920-b5c2-c83ec7b7a175",
   "metadata": {},
   "source": [
    "<h2>Phase One : Data Collection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a17597-1af9-4b21-bc1b-c90132e925a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_link = 'https://raw.githubusercontent.com/bishnu9009/Popular-ML-Datasets/main/boston_housing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647c568-0e3e-4cc6-adc9-f5feeaf9aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of DataFrame from our dataset using Pandas library.\n",
    "\n",
    "# boston_df = pd.read_csv('./BostonHousing.csv')     # Uncomment this line if you have the dataset locally downloaded and make sure to use the same file\n",
    "                                                     # name as that of your downlaoded dataset.\n",
    "boston_df = pd.read_csv(dataset_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97988e87-e7d3-4777-b5cc-b2fe7f9b48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the two datasets.\n",
    "print(\"Boston Housing Dataset first 10 Entries:\\n\")\n",
    "display(boston_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966227c-a37f-46b7-9e44-1706e4c20c52",
   "metadata": {},
   "source": [
    "<h3>Yap about the dataset here : </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa9914-7ad4-4bf6-8e61-4162d5b018f9",
   "metadata": {},
   "source": [
    "<h2>Phase Two : Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef95021-16ff-4157-ae74-d628c6e905c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for descriptive statistics of both datasets\n",
    "print(\"Descriptive Stats about Boston DF : \\n\")\n",
    "display(boston_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ac177-4c33-49e5-927a-9c80048d58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataTypes and other information about both datasets\n",
    "print(\"Information on Boston DF : \\n\")\n",
    "print(boston_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0235a8-925c-41e1-965c-9a725c3d9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing, NULL and NaN values in each dataset.\n",
    "\n",
    "# For Boston Dataset\n",
    "print(\"For Boston Dataset : \")\n",
    "for column in boston_df:\n",
    "    print(f\"Column {column} has {boston_df[column].isnull().sum()}\")\n",
    "print(\"Null/NaN value(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b98ac-994d-4d9e-b7da-5b43ace57d84",
   "metadata": {},
   "source": [
    "From the above analysis we can assess that : \n",
    "- Boston Dataset contains 5 missing values in the 'rm' row.\n",
    "\n",
    "Some considerations for the datasets : \n",
    "\n",
    "- The Boston Dataset's 'rm' row is average number of rooms per dwelling. Since it contains certain number of missing values we are going to use this column's mode value as our missing value imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83bd7a-8846-4ab7-826f-4a2171241728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value imputation for both dataframes.\n",
    "boston_rm_mode = boston_df['rm'].mode()[0]                          # mode() returns a Series, so we use [0] to get the first mode value\n",
    "boston_df['rm'].fillna(boston_rm_mode, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09536073-e982-4a15-a926-2b0a111c7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing, NULL and NaN values in each dataset after imputation\n",
    "\n",
    "# For Boston Dataset\n",
    "print(\"For Boston Dataset : \")\n",
    "for column in boston_df:\n",
    "    print(f\"Column {column} has {boston_df[column].isnull().sum()}\")\n",
    "print(\"Null/NaN value(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e3fef-1c55-4e6d-80e0-bdb233ec43a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First seven entries of the dataset.\n",
    "boston_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d48cf6-44e4-4ead-a4fe-3f25b18f5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation and Feature Scaling\n",
    "scaler = StandardScaler()          # scaler is an object of StandardScaler class which belongs to the Sklearn library.\n",
    "\n",
    "# Boston Dataset\n",
    "X_boston = boston_df.drop('medv', axis = 1)\n",
    "y_boston = boston_df['medv']\n",
    "\n",
    "X_boston_scaled = scaler.fit_transform(X_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b536e45-b372-4e70-affa-82d81aee513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting for training and testing.\n",
    "\n",
    "# For Boston Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_boston_scaled, y_boston, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd87a83a-633a-4057-9c7e-d0188325121b",
   "metadata": {},
   "source": [
    "<h2>Phase Three : Model Development</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30174f70-5bb3-4a7d-8955-9e60073a25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "\n",
    "## Boston Dataset\n",
    "print(\"Creating the model\")\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "print(\"Fitting the model\")\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Display the model coefficients\n",
    "coef_df = pd.DataFrame(linear_model.coef_, X_boston.columns, columns = ['Coefficient'])\n",
    "print(coef_df)\n",
    "\n",
    "# Predicting the ouput from test data.\n",
    "print(\"Predicting using the X_test\")\n",
    "y_pred_lm = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bc99b-63b5-4c0f-9e61-1c67a9db1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the linear regression model using plots\n",
    "\n",
    "# Plot actual vs. predicted prices\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.scatter(y_test, y_pred_lm, edgecolor = 'k', alpha = 0.7)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color = 'red', linewidth = 2)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs. Predicted Prices')\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize = (10, 6))\n",
    "residuals = y_test - y_pred_lm\n",
    "plt.scatter(y_pred_lm, residuals, edgecolor = 'k', alpha = 0.7)\n",
    "plt.axhline(y = 0, color = 'red', linewidth = 2)\n",
    "plt.xlabel('Predicted Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21c385-8f31-4fab-8371-3fecb1da0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestRegressor model\n",
    "\n",
    "## Boston dataset\n",
    "print(\"Creating the model\")\n",
    "random_regression = RandomForestRegressor()\n",
    "\n",
    "# Train the model\n",
    "print(\"Fitting the model\")\n",
    "random_regression.fit(X_train, y_train)\n",
    "\n",
    "# Display the model coefficients\n",
    "print(\"Predicting using the X_test\")\n",
    "y_pred_rf = random_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6352fc8-6022-47fe-9259-f54afa2df2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Random Forest regression model using plots\n",
    "\n",
    "# Plot actual vs. predicted prices\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.scatter(y_test, y_pred_rf, edgecolor = 'k', alpha = 0.7)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color = 'red', linewidth = 2)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs. Predicted Prices')\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize = (10, 6))\n",
    "residuals = y_test - y_pred_rf\n",
    "plt.scatter(y_pred_rf, residuals, edgecolor = 'k', alpha = 0.7)\n",
    "plt.axhline(y = 0, color = 'red', linewidth = 2)\n",
    "plt.xlabel('Predicted Prices')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76539cd-a1d0-4962-acc3-3c38c51e1383",
   "metadata": {},
   "source": [
    "<h2>Phase Four : Model Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e9a02-0fa0-49b7-8837-44f25595b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance Metrics for Linear Regression Model \\n\",\"--\"*25)\n",
    "print(f\"Linear Model R2 Score : {r2_score(y_test, y_pred_lm)}\")\n",
    "print(f\"Mean Absolute Error (MAE) : {mean_absolute_error(y_test, y_pred_lm)}\")\n",
    "print(f\"Mean Squared Error (MSE) : {mean_squared_error(y_test, y_pred_lm)}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) : {math.sqrt(mean_squared_error(y_test, y_pred_lm))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183d0dc-6419-4a5b-9942-27fefb460024",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance Metrics for Random Forest Regressor Model \\n\",\"--\"*25)\n",
    "print(f\"Linear Model R2 Score : {r2_score(y_test, y_pred_rf)}\")\n",
    "print(f\"Mean Absolute Error (MAE) : {mean_absolute_error(y_test, y_pred_rf)}\")\n",
    "print(f\"Mean Squared Error (MSE) : {mean_squared_error(y_test, y_pred_rf)}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) : {math.sqrt(mean_squared_error(y_test, y_pred_rf))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7661f-c2c0-4a83-b5cb-51aa54b712ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "metrics = {\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'R2': r2\n",
    "}\n",
    "joblib.dump(metrics, 'metrics.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a7073-b506-43b4-af7a-3ae7d9091e2f",
   "metadata": {},
   "source": [
    "<h3>Since we can observe that our 'Random Forest Regressor' model performs better than 'Linear Regression' model, we use that as our working model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44df980-6322-48ae-98da-01d6adc08c7a",
   "metadata": {},
   "source": [
    "<h2>Phase Five : Model Based Prediction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f8c74-a0c6-45cc-b9cf-a46d7adc43a6",
   "metadata": {},
   "source": [
    "<h3>The Below Code is for an Application developed using Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8885ef-46ca-46c9-b75a-48fd1162842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using joblib to store the random forest regression model to use in prediction.\n",
    "joblib.dump(random_regression, 'random_forest_model.pkl')\n",
    "print(\"File Created and Saved Sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d26d42-727b-4b3d-9b26-c9cacaaae486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plots for showing in our application\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.regplot(x = y_test, y = y_pred_rf, line_kws = {\"color\": \"red\"})\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "error = y_pred_rf - y_test\n",
    "sns.histplot(error, kde = True)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.title('Prediction Error Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319b95b-43b6-4b2c-9a36-aa8e97487dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min and max values for each feature in your dataset\n",
    "feature_min_max = {\n",
    "    'crim': (boston_df['crim'].min(), boston_df['crim'].max()),\n",
    "    'zn': (boston_df['zn'].min(), boston_df['zn'].max()),\n",
    "    'indus': (boston_df['indus'].min(), boston_df['indus'].max()),\n",
    "    'chas': (boston_df['chas'].min(), boston_df['chas'].max()),\n",
    "    'nox': (boston_df['nox'].min(), boston_df['nox'].max()),\n",
    "    'rm': (boston_df['rm'].min(), boston_df['rm'].max()),\n",
    "    'age': (boston_df['age'].min(), boston_df['age'].max()),\n",
    "    'dis': (boston_df['dis'].min(), boston_df['dis'].max()),\n",
    "    'rad': (boston_df['rad'].min(), boston_df['rad'].max()),\n",
    "    'tax': (boston_df['tax'].min(), boston_df['tax'].max()),\n",
    "    'ptratio': (boston_df['ptratio'].min(), boston_df['ptratio'].max()),\n",
    "    'b': (boston_df['b'].min(), boston_df['b'].max()),\n",
    "    'lstat': (boston_df['lstat'].min(), boston_df['lstat'].max())\n",
    "}\n",
    "\n",
    "# Save the feature min and max values\n",
    "joblib.dump(feature_min_max, 'feature_min_max.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bffcff-28c7-4ddb-a4ca-6311c29e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained model and feature min/max values\n",
    "model = joblib.load('random_forest_model.pkl')\n",
    "feature_min_max = joblib.load('feature_min_max.pkl')\n",
    "\n",
    "st.set_page_config(page_title=\"Housing Price Prediction App\", page_icon = \":house:\",layout = \"wide\")\n",
    "\n",
    "st.title('Boston Housing Price Prediction')\n",
    "\n",
    "st.sidebar.header('Input Features')\n",
    "\n",
    "# Function to get user input for prediction\n",
    "def user_input_features():\n",
    "    crim = st.sidebar.slider('crim', feature_min_max['crim'][0], feature_min_max['crim'][1], value=feature_min_max['crim'][0])\n",
    "    zn = st.sidebar.slider('zn', feature_min_max['zn'][0], feature_min_max['zn'][1], value=feature_min_max['zn'][0])\n",
    "    indus = st.sidebar.slider('indus', feature_min_max['indus'][0], feature_min_max['indus'][1], value=feature_min_max['indus'][0])\n",
    "    chas = st.sidebar.selectbox('chas', [0, 1])\n",
    "    nox = st.sidebar.slider('nox', feature_min_max['nox'][0], feature_min_max['nox'][1], value=feature_min_max['nox'][0])\n",
    "    rm = st.sidebar.slider('rm', feature_min_max['rm'][0], feature_min_max['rm'][1], value=feature_min_max['rm'][0])\n",
    "    age = st.sidebar.slider('age', feature_min_max['age'][0], feature_min_max['age'][1], value=feature_min_max['age'][0])\n",
    "    dis = st.sidebar.slider('dis', feature_min_max['dis'][0], feature_min_max['dis'][1], value=feature_min_max['dis'][0])\n",
    "    rad = st.sidebar.slider('rad', feature_min_max['rad'][0], feature_min_max['rad'][1], value=feature_min_max['rad'][0])\n",
    "    tax = st.sidebar.slider('tax', feature_min_max['tax'][0], feature_min_max['tax'][1], value=feature_min_max['tax'][0])\n",
    "    ptratio = st.sidebar.slider('ptratio', feature_min_max['ptratio'][0], feature_min_max['ptratio'][1], value=feature_min_max['ptratio'][0])\n",
    "    b = st.sidebar.slider('b', feature_min_max['b'][0], feature_min_max['b'][1], value=feature_min_max['b'][0])\n",
    "    lstat = st.sidebar.slider('lstat', feature_min_max['lstat'][0], feature_min_max['lstat'][1], value=feature_min_max['lstat'][0])\n",
    "    \n",
    "    data = {\n",
    "        'crim': crim,\n",
    "        'zn': zn,\n",
    "        'indus': indus,\n",
    "        'chas': chas,\n",
    "        'nox': nox,\n",
    "        'rm': rm,\n",
    "        'age': age,\n",
    "        'dis': dis,\n",
    "        'rad': rad,\n",
    "        'tax': tax,\n",
    "        'ptratio': ptratio,\n",
    "        'b': b,\n",
    "        'lstat': lstat\n",
    "    }\n",
    "    \n",
    "    features = np.array([list(data.values())])\n",
    "    return features\n",
    "\n",
    "input_df = user_input_features()\n",
    "\n",
    "# Predict button\n",
    "if st.sidebar.button('Predict'):\n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_df)\n",
    "    \n",
    "    st.subheader('Prediction')\n",
    "    st.write(f'The predicted median value of owner-occupied homes in $1000s is: {prediction[0]:.2f}')\n",
    "    \n",
    "# Display model performance metrics\n",
    "st.subheader('Model Performance Metrics')\n",
    "metrics = joblib.load('metrics.pkl')\n",
    "st.write(f\"Mean Absolute Error (MAE): {metrics['MAE']:.2f}\")\n",
    "st.write(f\"Mean Squared Error (MSE): {metrics['MSE']:.2f}\")\n",
    "st.write(f\"Root Mean Squared Error (RMSE): {metrics['RMSE']:.2f}\")\n",
    "st.write(f\"R-squared (R2): {metrics['R2']:.2f}\")\n",
    "\n",
    "# Display model performance plots\n",
    "st.subheader('Model Performance Plots')\n",
    "st.image('model_performance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f76542-52ce-408b-b7f7-74118ba7425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The running application can be stopped by cllicking on this cell and pressing \"I + I\" or stopping the kernel of the ipynb file.\n",
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
